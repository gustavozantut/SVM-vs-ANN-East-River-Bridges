{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM e ANN\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Na cidade de Nova Iorque, a estimação da quantidade de ciclistas faz parte do planejamento do sistema de transporte público urbano. Neste contexto a quantidade de ciclistas passando pelas pontes do East River são contadas diariamente.\n",
    "Essa base de dados foi disponibilizada pela prefeitura de Nova Iorque e foi limpada para ser postada no Kaggle.\n",
    "\n",
    "Nesse contexto a base de dados [New York City - East River Bicycle Crossings](https://www.kaggle.com/new-york-city/nyc-east-river-bicycle-crossings) permite uma análise da quantidade de ciclistas que passam pela ponte.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## East River Bicycle Crossings\n",
    "### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Day</th>\n",
       "      <th>High Temp (°F)</th>\n",
       "      <th>Low Temp (°F)</th>\n",
       "      <th>Precipitation</th>\n",
       "      <th>Brooklyn Bridge</th>\n",
       "      <th>Manhattan Bridge</th>\n",
       "      <th>Williamsburg Bridge</th>\n",
       "      <th>Queensboro Bridge</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>2016-04-01 00:00:00</td>\n",
       "      <td>78.1</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1704.0</td>\n",
       "      <td>3126</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>2552.0</td>\n",
       "      <td>11497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-04-02 00:00:00</td>\n",
       "      <td>2016-04-02 00:00:00</td>\n",
       "      <td>55.0</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.15</td>\n",
       "      <td>827.0</td>\n",
       "      <td>1646</td>\n",
       "      <td>2565.0</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>6922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-04-03 00:00:00</td>\n",
       "      <td>2016-04-03 00:00:00</td>\n",
       "      <td>39.9</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>526.0</td>\n",
       "      <td>1232</td>\n",
       "      <td>1695.0</td>\n",
       "      <td>1306.0</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-04-04 00:00:00</td>\n",
       "      <td>2016-04-04 00:00:00</td>\n",
       "      <td>44.1</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.47 (S)</td>\n",
       "      <td>521.0</td>\n",
       "      <td>1067</td>\n",
       "      <td>1440.0</td>\n",
       "      <td>1307.0</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-04-05 00:00:00</td>\n",
       "      <td>2016-04-05 00:00:00</td>\n",
       "      <td>42.1</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0</td>\n",
       "      <td>1416.0</td>\n",
       "      <td>2617</td>\n",
       "      <td>3081.0</td>\n",
       "      <td>2357.0</td>\n",
       "      <td>9471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                  Day  High Temp (°F)  Low Temp (°F)  \\\n",
       "0  2016-04-01 00:00:00  2016-04-01 00:00:00            78.1           66.0   \n",
       "1  2016-04-02 00:00:00  2016-04-02 00:00:00            55.0           48.9   \n",
       "2  2016-04-03 00:00:00  2016-04-03 00:00:00            39.9           34.0   \n",
       "3  2016-04-04 00:00:00  2016-04-04 00:00:00            44.1           33.1   \n",
       "4  2016-04-05 00:00:00  2016-04-05 00:00:00            42.1           26.1   \n",
       "\n",
       "  Precipitation  Brooklyn Bridge  Manhattan Bridge  Williamsburg Bridge  \\\n",
       "0          0.01           1704.0              3126               4115.0   \n",
       "1          0.15            827.0              1646               2565.0   \n",
       "2          0.09            526.0              1232               1695.0   \n",
       "3      0.47 (S)            521.0              1067               1440.0   \n",
       "4             0           1416.0              2617               3081.0   \n",
       "\n",
       "   Queensboro Bridge  Total  \n",
       "0             2552.0  11497  \n",
       "1             1884.0   6922  \n",
       "2             1306.0   4759  \n",
       "3             1307.0   4335  \n",
       "4             2357.0   9471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape: (210, 10)\n"
     ]
    }
   ],
   "source": [
    "X = pd.read_csv('nyc-east-river-bicycle-counts.csv', index_col=0)\n",
    "display(X.head())\n",
    "print(f'Dataframe shape: {X.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features data shape: (203, 3)\n",
      "Target data shape: (203, 5)\n"
     ]
    }
   ],
   "source": [
    "X['Precipitation'] = np.where(X['Precipitation'] == '0.47 (S)', '0.47', X['Precipitation'])\n",
    "X.drop(X[X.Precipitation == 'T'].index,inplace=True)\n",
    "y = X[['Brooklyn Bridge', 'Manhattan Bridge', 'Williamsburg Bridge','Queensboro Bridge', 'Total']]\n",
    "X.drop(['Brooklyn Bridge', 'Manhattan Bridge', 'Williamsburg Bridge','Queensboro Bridge', 'Total','Day','Date'], inplace=True, axis=1)\n",
    "print(f'Features data shape: {X.shape}')\n",
    "print(f'Target data shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High Temp (°F)</th>\n",
       "      <th>Low Temp (°F)</th>\n",
       "      <th>Precipitation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>57.0</td>\n",
       "      <td>39.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>57.0</td>\n",
       "      <td>53.1</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>57.0</td>\n",
       "      <td>46.9</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>66.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>64.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     High Temp (°F)  Low Temp (°F) Precipitation\n",
       "12             57.0           39.9             0\n",
       "156            57.0           53.1          0.09\n",
       "28             57.0           46.9          0.05\n",
       "84             66.9           54.0             0\n",
       "149            64.0           48.0             0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brooklyn Bridge Training scores\n",
      "mae: 837.0018271492429\n",
      "mse: 964568.8591974631\n",
      "R2: 0.002753737636042586\n",
      " Test scores\n",
      "mae: 825.1076469036552\n",
      "mse: 1029491.3985823691\n",
      "R2: -0.05484156955482322 \n",
      "\n",
      "Manhattan Bridge Training scores\n",
      "mae: 1459.3431476854996\n",
      "mse: 2974371.7859095815\n",
      "R2: 0.005240438762876276\n",
      " Test scores\n",
      "mae: 1384.6223710714291\n",
      "mse: 2926940.043950223\n",
      "R2: -0.05904957688729073 \n",
      "\n",
      "Williamsburg Bridge Training scores\n",
      "mae: 1512.7734320875143\n",
      "mse: 3310750.774057435\n",
      "R2: -0.000155752038129231\n",
      " Test scores\n",
      "mae: 1531.205207879265\n",
      "mse: 3571937.180246939\n",
      "R2: -0.0800357972688388 \n",
      "\n",
      "Queensboro Bridge Training scores\n",
      "mae: 938.7857777665268\n",
      "mse: 1200216.092061242\n",
      "R2: 0.010731748021516219\n",
      " Test scores\n",
      "mae: 938.034476171948\n",
      "mse: 1299116.4909557593\n",
      "R2: -0.010300912155091657 \n",
      "\n",
      "Total Training scores\n",
      "mae: 4761.483308630724\n",
      "mse: 31419912.81791413\n",
      "R2: -0.0007372070109119555\n",
      " Test scores\n",
      "mae: 4697.86374446463\n",
      "mse: 33070664.49172937\n",
      "R2: -0.06315437105050892 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "for i in y_train.columns:\n",
    "    svr = SVR()\n",
    "    svr.fit(X_train, y_train[i])\n",
    "\n",
    "    print(i+' Training scores')\n",
    "    y_hat = svr.predict(X_train)\n",
    "    mae = mean_absolute_error(y_train[i], y_hat)\n",
    "    print('mae:', mae)\n",
    "    mse = mean_squared_error(y_train[i], y_hat)\n",
    "    print('mse:', mse)\n",
    "    r2 = r2_score(y_train[i], y_hat)\n",
    "    print('R2:', r2)\n",
    "\n",
    "    print(' Test scores')\n",
    "    y_pred = svr.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test[i], y_pred)\n",
    "    print('mae:', mae)\n",
    "    mse = mean_squared_error(y_test[i], y_pred)\n",
    "    print('mse:', mse)\n",
    "    r2 = r2_score(y_test[i], y_pred)\n",
    "    print('R2:', r2,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um grid aleatorizado\n",
    "tuned_parameters =[\n",
    "    {'kernel': ['rbf'],\n",
    "     'gamma': [1e-2, 1e-1, 1],\n",
    "     'C': [1, 10, 100, 1000]\n",
    "    },\n",
    "    {'kernel': ['linear'], \n",
    "     'C': [1, 10, 100, 1000]\n",
    "    },\n",
    "    {'kernel': ['poly'],\n",
    "     'degree': [2,3,4],\n",
    "     'C': [1, 10, 100, 1000]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n",
      "Brooklyn Bridge 0 \n",
      " RandomizedSearchCV(cv=5, error_score=nan,\n",
      "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
      "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
      "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
      "                                 verbose=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
      "                   param_distributions=[{'C': [1, 10, 100, 1000],\n",
      "                                         'gamma': [0.01, 0.1, 1],\n",
      "                                         'kernel': ['rbf']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'kernel': ['linear']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'degree': [2, 3, 4],\n",
      "                                         'kernel': ['poly']}],\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
      "                   verbose=0)\n",
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n",
      "Manhattan Bridge 1 \n",
      " RandomizedSearchCV(cv=5, error_score=nan,\n",
      "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
      "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
      "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
      "                                 verbose=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
      "                   param_distributions=[{'C': [1, 10, 100, 1000],\n",
      "                                         'gamma': [0.01, 0.1, 1],\n",
      "                                         'kernel': ['rbf']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'kernel': ['linear']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'degree': [2, 3, 4],\n",
      "                                         'kernel': ['poly']}],\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
      "                   verbose=0)\n",
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n",
      "Williamsburg Bridge 2 \n",
      " RandomizedSearchCV(cv=5, error_score=nan,\n",
      "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
      "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
      "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
      "                                 verbose=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
      "                   param_distributions=[{'C': [1, 10, 100, 1000],\n",
      "                                         'gamma': [0.01, 0.1, 1],\n",
      "                                         'kernel': ['rbf']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'kernel': ['linear']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'degree': [2, 3, 4],\n",
      "                                         'kernel': ['poly']}],\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
      "                   verbose=0)\n",
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n",
      "Queensboro Bridge 3 \n",
      " RandomizedSearchCV(cv=5, error_score=nan,\n",
      "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
      "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
      "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
      "                                 verbose=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
      "                   param_distributions=[{'C': [1, 10, 100, 1000],\n",
      "                                         'gamma': [0.01, 0.1, 1],\n",
      "                                         'kernel': ['rbf']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'kernel': ['linear']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'degree': [2, 3, 4],\n",
      "                                         'kernel': ['poly']}],\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
      "                   verbose=0)\n",
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n",
      "Total 4 \n",
      " RandomizedSearchCV(cv=5, error_score=nan,\n",
      "                   estimator=SVR(C=1.0, cache_size=200, coef0=0.0, degree=3,\n",
      "                                 epsilon=0.1, gamma='scale', kernel='rbf',\n",
      "                                 max_iter=-1, shrinking=True, tol=0.001,\n",
      "                                 verbose=False),\n",
      "                   iid='deprecated', n_iter=10, n_jobs=None,\n",
      "                   param_distributions=[{'C': [1, 10, 100, 1000],\n",
      "                                         'gamma': [0.01, 0.1, 1],\n",
      "                                         'kernel': ['rbf']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'kernel': ['linear']},\n",
      "                                        {'C': [1, 10, 100, 1000],\n",
      "                                         'degree': [2, 3, 4],\n",
      "                                         'kernel': ['poly']}],\n",
      "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
      "                   verbose=0)\n"
     ]
    }
   ],
   "source": [
    "lista={}\n",
    "for i,j in zip(y_train.columns, range(0, len(y_train.columns))):\n",
    "    scores = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']\n",
    "\n",
    "    score = scores[0]\n",
    "    print(\"# Ajuste dos hyper-parâmetros (%s)\" % score)\n",
    "    print()\n",
    "    \n",
    "    svr_cv = RandomizedSearchCV(\n",
    "        SVR(), tuned_parameters, cv=5, scoring=score, refit=True\n",
    "    )\n",
    "    lista[j]=svr_cv\n",
    "    print(i,j,\"\\n\",svr_cv.fit(X_train, y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'kernel': 'linear', 'C': 1000}\n",
      "{'kernel': 'linear', 'C': 10}\n",
      "{'kernel': 'rbf', 'gamma': 1, 'C': 1000}\n",
      "{'kernel': 'rbf', 'gamma': 0.1, 'C': 1000}\n",
      "{'kernel': 'linear', 'C': 1000}\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,len(lista)):\n",
    "    print(lista[i].best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brooklyn Bridge \n",
      " Training scores\n",
      "mae: 471.2547954290519\n",
      "mse: 380118.66582141543\n",
      "R2: 0.6070037767333951\n",
      "Test scores\n",
      "mae: 344.44011429679955\n",
      "mse: 178907.81104554178\n",
      "R2: 0.8166867673991569\n",
      "Brooklyn Bridge 0\n",
      "\n",
      "\n",
      "Manhattan Bridge \n",
      " Training scores\n",
      "mae: 963.6660055761893\n",
      "mse: 1413854.2723730314\n",
      "R2: 0.5271455094142073\n",
      "Test scores\n",
      "mae: 888.6078333733941\n",
      "mse: 1056444.1252259265\n",
      "R2: 0.6177486771079863\n",
      "Manhattan Bridge 1\n",
      "\n",
      "\n",
      "Williamsburg Bridge \n",
      " Training scores\n",
      "mae: 7.033473969397888\n",
      "mse: 2597.3543182730045\n",
      "R2: 0.9992153565644816\n",
      "Test scores\n",
      "mae: 36.62759972489505\n",
      "mse: 13683.580072741626\n",
      "R2: 0.9958625374502432\n",
      "Williamsburg Bridge 2\n",
      "\n",
      "\n",
      "Queensboro Bridge \n",
      " Training scores\n",
      "mae: 44.885344237390285\n",
      "mse: 29376.902907230062\n",
      "R2: 0.9757863291620538\n",
      "Test scores\n",
      "mae: 76.60818446156563\n",
      "mse: 47391.0239283341\n",
      "R2: 0.9631448026130935\n",
      "Queensboro Bridge 3\n",
      "\n",
      "\n",
      "Total \n",
      " Training scores\n",
      "mae: 2865.1717669448417\n",
      "mse: 12862469.407034772\n",
      "R2: 0.5903250341827713\n",
      "Test scores\n",
      "mae: 2625.9735526621034\n",
      "mse: 9898304.65127032\n",
      "R2: 0.6817897064445311\n",
      "Total 4\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i,j in zip(y_train.columns, range(0, len(y_train.columns))):\n",
    "    print(i,\"\\n\",'Training scores')\n",
    "    y_hat = lista[j].predict(X_train)\n",
    "    mae = mean_absolute_error(y_train[i], y_hat)\n",
    "    print('mae:', mae)\n",
    "    mse = mean_squared_error(y_train[i], y_hat)\n",
    "    print('mse:', mse)\n",
    "    r2 = r2_score(y_train[i], y_hat)\n",
    "    print('R2:', r2)\n",
    "\n",
    "    print('Test scores')\n",
    "    y_pred = lista[j].predict(X_test)\n",
    "    mae = mean_absolute_error(y_test[i], y_pred)\n",
    "    print('mae:', mae)\n",
    "    mse = mean_squared_error(y_test[i], y_pred)\n",
    "    print('mse:', mse)\n",
    "    r2 = r2_score(y_test[i], y_pred)\n",
    "    print('R2:', r2)\n",
    "    print(i,j)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "mae: 1508.0638161202708\n",
      "mse: 5116743.721818784\n",
      "R2: 0.35450505655045284\n",
      "Test scores\n",
      "mae: 1239.0637742440788\n",
      "mse: 3707581.006350218\n",
      "R2: 0.5262470892302462\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "annr = MLPRegressor(max_iter=10000, learning_rate_init=0.01)\n",
    "annr.fit(X_train, y_train)\n",
    "\n",
    "print('Training scores')\n",
    "y_hat = annr.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_hat)\n",
    "print('mae:', mae)\n",
    "mse = mean_squared_error(y_train, y_hat)\n",
    "print('mse:', mse)\n",
    "r2 = r2_score(y_train, y_hat)\n",
    "print('R2:', r2)\n",
    "\n",
    "print('Test scores')\n",
    "y_pred = annr.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('mae:', mae)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse:', mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação de um grid aleatorizado\n",
    "tuned_parameters =[\n",
    "    {\n",
    "        'solver': ['adam'],\n",
    "        'hidden_layer_sizes': [1, 10, 100, 1000],\n",
    "        'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "        'learning_rate_init': [1e-3, 1e-2, 1e-1, 1]\n",
    "    },\n",
    "     {\n",
    "        'solver': ['lbfgs'],\n",
    "        'hidden_layer_sizes': [1, 10, 100, 1000],\n",
    "        'activation': ['relu', 'identity', 'logistic', 'tanh'],\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Ajuste dos hyper-parâmetros (neg_mean_squared_error)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "G:\\ANACONDA\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score=nan,\n",
       "                   estimator=MLPRegressor(activation='relu', alpha=0.0001,\n",
       "                                          batch_size='auto', beta_1=0.9,\n",
       "                                          beta_2=0.999, early_stopping=False,\n",
       "                                          epsilon=1e-08,\n",
       "                                          hidden_layer_sizes=(100,),\n",
       "                                          learning_rate='constant',\n",
       "                                          learning_rate_init=0.001,\n",
       "                                          max_fun=15000, max_iter=10000,\n",
       "                                          momentum=0.9, n_iter_no_change=10,\n",
       "                                          nesterovs_momentum=True, power_t=0.5,\n",
       "                                          rand...\n",
       "                   param_distributions=[{'activation': ['relu', 'identity',\n",
       "                                                        'logistic', 'tanh'],\n",
       "                                         'hidden_layer_sizes': [1, 10, 100,\n",
       "                                                                1000],\n",
       "                                         'learning_rate_init': [0.001, 0.01,\n",
       "                                                                0.1, 1],\n",
       "                                         'solver': ['adam']},\n",
       "                                        {'activation': ['relu', 'identity',\n",
       "                                                        'logistic', 'tanh'],\n",
       "                                         'hidden_layer_sizes': [1, 10, 100,\n",
       "                                                                1000],\n",
       "                                         'solver': ['lbfgs']}],\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = ['neg_mean_squared_error', 'neg_mean_absolute_error', 'r2']\n",
    "\n",
    "score = scores[0]\n",
    "print(\"# Ajuste dos hyper-parâmetros (%s)\" % score)\n",
    "print()\n",
    "\n",
    "annr_cv = RandomizedSearchCV(\n",
    "    MLPRegressor(max_iter=10000), tuned_parameters, cv=10, scoring=score, refit=True\n",
    ")\n",
    "annr_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'solver': 'lbfgs', 'hidden_layer_sizes': 100, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "print(annr_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training scores\n",
      "mae: 1136.360875996174\n",
      "mse: 3710278.225853692\n",
      "R2: 0.5329005481634793\n",
      "Test scores\n",
      "mae: 1274.4574683417059\n",
      "mse: 4195933.967073979\n",
      "R2: 0.462178733373862\n"
     ]
    }
   ],
   "source": [
    "print('Training scores')\n",
    "y_hat = annr_cv.predict(X_train)\n",
    "mae = mean_absolute_error(y_train, y_hat)\n",
    "print('mae:', mae)\n",
    "mse = mean_squared_error(y_train, y_hat)\n",
    "print('mse:', mse)\n",
    "r2 = r2_score(y_train, y_hat)\n",
    "print('R2:', r2)\n",
    "\n",
    "print('Test scores')\n",
    "y_pred = annr_cv.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "print('mae:', mae)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('mse:', mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('R2:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
